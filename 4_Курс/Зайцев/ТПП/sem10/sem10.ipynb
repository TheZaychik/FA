{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35dae6db",
   "metadata": {},
   "source": [
    "Медианный фильтр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa3bb46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageio\n",
      "  Downloading imageio-2.34.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from imageio) (1.23.4)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from imageio) (9.5.0)\n",
      "Downloading imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.4/313.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imageio\n",
      "Successfully installed imageio-2.34.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b28d3b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imageio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imread, imsave\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyopencl\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcl\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Read in image\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imageio'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imageio import imread, imsave\n",
    "\n",
    "import pyopencl as cl\n",
    "\n",
    "# Read in image\n",
    "img = imread(\"noisyImage.jpg\").astype(np.float32)\n",
    "print(img.shape)\n",
    "\n",
    "img = np.mean(img, axis=2)\n",
    "print(img.shape)\n",
    "\n",
    "ctx = cl.create_some_context()\n",
    "queue = cl.CommandQueue(ctx)\n",
    "\n",
    "mf = cl.mem_flags\n",
    "\n",
    "# Kernel function\n",
    "src = \"\"\"\n",
    "void sort(int *a, int *b, int *c) {\n",
    "   int swap;\n",
    "   if(*a > *b) {\n",
    "      swap = *a;\n",
    "      *a = *b;\n",
    "      *b = swap;\n",
    "   }\n",
    "   if(*a > *c) {\n",
    "      swap = *a;\n",
    "      *a = *c;\n",
    "      *c = swap;\n",
    "   }\n",
    "   if(*b > *c) {\n",
    "      swap = *b;\n",
    "      *b = *c;\n",
    "      *c = swap;\n",
    "   }\n",
    "}\n",
    "__kernel void medianFilter(\n",
    "    __global float *img, __global float *result, __global int *width, __global\n",
    "    int *height)\n",
    "{\n",
    "    int w = *width;\n",
    "    int h = *height;\n",
    "    int posx = get_global_id(1);\n",
    "    int posy = get_global_id(0);\n",
    "    int i = w*posy + posx;\n",
    "    // Keeping the edge pixels the same\n",
    "    if( posx == 0 || posy == 0 || posx == w-1 || posy == h-1 )\n",
    "    {\n",
    "        result[i] = img[i];\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        int pixel00, pixel01, pixel02, pixel10, pixel11, pixel12, pixel20,\n",
    "            pixel21, pixel22;\n",
    "        pixel00 = img[i - 1 - w];\n",
    "        pixel01 = img[i- w];\n",
    "        pixel02 = img[i + 1 - w];\n",
    "        pixel10 = img[i - 1];\n",
    "        pixel11 = img[i];\n",
    "        pixel12 = img[i + 1];\n",
    "        pixel20 = img[i - 1 + w];\n",
    "        pixel21 = img[i + w];\n",
    "        pixel22 = img[i + 1 + w];\n",
    "        //sort the rows\n",
    "        sort( &(pixel00), &(pixel01), &(pixel02) );\n",
    "        sort( &(pixel10), &(pixel11), &(pixel12) );\n",
    "        sort( &(pixel20), &(pixel21), &(pixel22) );\n",
    "        //sort the columns\n",
    "        sort( &(pixel00), &(pixel10), &(pixel20) );\n",
    "        sort( &(pixel01), &(pixel11), &(pixel21) );\n",
    "        sort( &(pixel02), &(pixel12), &(pixel22) );\n",
    "        //sort the diagonal\n",
    "        sort( &(pixel00), &(pixel11), &(pixel22) );\n",
    "        // median is the the middle value of the diagonal\n",
    "        result[i] = pixel11;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Kernel function instantiation\n",
    "prg = cl.Program(ctx, src).build()\n",
    "# Allocate memory for variables on the device\n",
    "img_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=img)\n",
    "result_g = cl.Buffer(ctx, mf.WRITE_ONLY, img.nbytes)\n",
    "width_g = cl.Buffer(\n",
    "    ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=np.int32(img.shape[1])\n",
    ")\n",
    "height_g = cl.Buffer(\n",
    "    ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=np.int32(img.shape[0])\n",
    ")\n",
    "# Call Kernel. Automatically takes care of block/grid distribution\n",
    "prg.medianFilter(queue, img.shape, None, img_g, result_g, width_g, height_g)\n",
    "result = np.empty_like(img)\n",
    "cl.enqueue_copy(queue, result, result_g)\n",
    "\n",
    "# Show the blurred image\n",
    "imsave(\"medianFilter-OpenCL.jpg\", result, mode=\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f03a0d5",
   "metadata": {},
   "source": [
    "Умножение матриц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfab21ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "LogicError",
     "evalue": "clEnqueueNDRangeKernel failed: INVALID_WORK_ITEM_SIZE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 186\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# warmup ----------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[43md_c_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_a_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_b_buf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     event\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m    190\u001b[0m queue\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyopencl/__init__.py:901\u001b[0m, in \u001b[0;36m_add_functionality.<locals>.kernel_call\u001b[0;34m(self, queue, global_size, local_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkernel_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, queue, global_size, local_size, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;66;03m# __call__ can't be overridden directly, so we need this\u001b[39;00m\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;66;03m# trampoline hack.\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \n\u001b[1;32m    899\u001b[0m     \u001b[38;5;66;03m# Note: This is only used for the generic __call__, before\u001b[39;00m\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;66;03m# kernel_set_scalar_arg_dtypes is called.\u001b[39;00m\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_enqueue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<pyopencl invoker for 'matrixMul'>:8\u001b[0m, in \u001b[0;36menqueue_knl_matrixMul\u001b[0;34m(self, queue, global_size, local_size, arg0, arg1, arg2, global_offset, g_times_l, allow_empty_ndrange, wait_for)\u001b[0m\n",
      "\u001b[0;31mLogicError\u001b[0m: clEnqueueNDRangeKernel failed: INVALID_WORK_ITEM_SIZE"
     ]
    }
   ],
   "source": [
    "# example provided by Eilif Muller\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "KERNEL_CODE = \"\"\"\n",
    "\n",
    "// Thread block size\n",
    "#define BLOCK_SIZE %(block_size)d\n",
    "\n",
    "// Matrix dimensions\n",
    "// (chosen as multiples of the thread block size for simplicity)\n",
    "#define WA %(w_a)d // Matrix A width\n",
    "#define HA %(h_a)d // Matrix A height\n",
    "#define WB %(w_b)d // Matrix B width\n",
    "#define HB WA  // Matrix B height\n",
    "#define WC WB  // Matrix C width\n",
    "#define HC HA  // Matrix C height\n",
    "\n",
    "\n",
    "/*\n",
    " * Copyright 1993-2009 NVIDIA Corporation.  All rights reserved.\n",
    " *\n",
    " * NVIDIA Corporation and its licensors retain all intellectual property and\n",
    " * proprietary rights in and to this software and related documentation.\n",
    " * Any use, reproduction, disclosure, or distribution of this software\n",
    " * and related documentation without an express license agreement from\n",
    " * NVIDIA Corporation is strictly prohibited.\n",
    " *\n",
    " * Please refer to the applicable NVIDIA end user license agreement (EULA)\n",
    " * associated with this source code for terms and conditions that govern\n",
    " * your use of this NVIDIA software.\n",
    " *\n",
    " */\n",
    "\n",
    "/* Matrix multiplication: C = A * B.\n",
    " * Device code.\n",
    " */\n",
    "\n",
    "#define AS(j, i) As[i + j * BLOCK_SIZE]\n",
    "#define BS(j, i) Bs[i + j * BLOCK_SIZE]\n",
    "\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "//! Matrix multiplication on the device: C = A * B\n",
    "//! WA is A's width and WB is B's width\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "__kernel __attribute__((reqd_work_group_size(16,16,1))) \n",
    "void\n",
    "matrixMul( __global float* C, __global float* A, __global float* B)\n",
    "{\n",
    "    __local float As[BLOCK_SIZE*BLOCK_SIZE];\n",
    "    __local float Bs[BLOCK_SIZE*BLOCK_SIZE];\n",
    "\n",
    "    // Block index\n",
    "    int bx = get_group_id(0);\n",
    "    int by = get_group_id(1);\n",
    "\n",
    "    // Thread index\n",
    "    int tx = get_local_id(0);\n",
    "    int ty = get_local_id(1);\n",
    "\n",
    "    // Index of the first sub-matrix of A processed by the block\n",
    "    int aBegin = WA * BLOCK_SIZE * by;\n",
    "\n",
    "    // Index of the last sub-matrix of A processed by the block\n",
    "    int aEnd   = aBegin + WA - 1;\n",
    "\n",
    "    // Step size used to iterate through the sub-matrices of A\n",
    "    int aStep  = BLOCK_SIZE;\n",
    "\n",
    "    // Index of the first sub-matrix of B processed by the block\n",
    "    int bBegin = BLOCK_SIZE * bx;\n",
    "\n",
    "    // Step size used to iterate through the sub-matrices of B\n",
    "    int bStep  = BLOCK_SIZE * WB;\n",
    "\n",
    "    // Csub is used to store the element of the block sub-matrix\n",
    "    // that is computed by the thread\n",
    "    float Csub = 0.0f;\n",
    "\n",
    "    // Loop over all the sub-matrices of A and B\n",
    "    // required to compute the block sub-matrix\n",
    "    for (int a = aBegin, b = bBegin;\n",
    "             a <= aEnd;\n",
    "             a += aStep, b += bStep) {\n",
    "\n",
    "        // Load the matrices from device memory\n",
    "        // to shared memory; each thread loads\n",
    "        // one element of each matrix\n",
    "        AS(ty, tx) = A[a + WA * ty + tx];\n",
    "        BS(ty, tx) = B[b + WB * ty + tx];\n",
    "\n",
    "        // Synchronize to make sure the matrices are loaded\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "\n",
    "        // Multiply the two matrices together;\n",
    "        // each thread computes one element\n",
    "        // of the block sub-matrix\n",
    "        for (int k = 0; k < BLOCK_SIZE; ++k)\n",
    "            Csub += AS(ty, k) * BS(k, tx);\n",
    "\n",
    "        // Synchronize to make sure that the preceding\n",
    "        // computation is done before loading two new\n",
    "        // sub-matrices of A and B in the next iteration\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "    }\n",
    "\n",
    "    // Write the block sub-matrix to device memory;\n",
    "    // each thread writes one element\n",
    "    C[get_global_id(1) * get_global_size(0) + get_global_id(0)] = Csub;\n",
    "\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pyopencl as cl\n",
    "from time import time\n",
    "import numpy\n",
    "\n",
    "block_size = 16\n",
    "\n",
    "ctx = cl.create_some_context()\n",
    "\n",
    "for dev in ctx.devices:\n",
    "    assert dev.local_mem_size > 0\n",
    "\n",
    "queue = cl.CommandQueue(ctx,\n",
    "        properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
    "\n",
    "#queue = cl.CommandQueue(ctx)\n",
    "\n",
    "if False:\n",
    "    a_height = 4096\n",
    "    #a_height = 1024\n",
    "    a_width = 2048\n",
    "    #a_width = 256\n",
    "    #b_height == a_width\n",
    "    b_width = a_height\n",
    "\n",
    "elif False:\n",
    "    # like PyCUDA\n",
    "    a_height = 2516\n",
    "    a_width = 1472\n",
    "    b_height = a_width\n",
    "    b_width = 2144\n",
    "\n",
    "else:\n",
    "    # CL SDK\n",
    "    a_width = 50*block_size\n",
    "    a_height = 100*block_size\n",
    "    b_width = 50*block_size\n",
    "    b_height = a_width\n",
    "\n",
    "c_width = b_width\n",
    "c_height = a_height\n",
    "\n",
    "h_a = numpy.random.rand(a_height, a_width).astype(numpy.float32)\n",
    "h_b = numpy.random.rand(b_height, b_width).astype(numpy.float32)\n",
    "h_c = numpy.empty((c_height, c_width)).astype(numpy.float32)\n",
    "\n",
    "\n",
    "kernel_params = {\"block_size\": block_size,\n",
    "        \"w_a\":a_width, \"h_a\":a_height, \"w_b\":b_width}\n",
    "\n",
    "prg = cl.Program(ctx, KERNEL_CODE % kernel_params,\n",
    "        ).build(options=\"-cl-mad-enable -cl-fast-relaxed-math\")\n",
    "kernel = prg.matrixMul\n",
    "#print prg.binaries[0]\n",
    "\n",
    "assert a_width % block_size == 0\n",
    "assert a_height % block_size == 0\n",
    "assert b_width % block_size == 0\n",
    "\n",
    "# transfer host -> device -----------------------------------------------------\n",
    "mf = cl.mem_flags\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "d_a_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=h_a)\n",
    "d_b_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=h_b)\n",
    "d_c_buf = cl.Buffer(ctx, mf.WRITE_ONLY, size=h_c.nbytes)\n",
    "\n",
    "push_time = time()-t1\n",
    "\n",
    "# warmup ----------------------------------------------------------------------\n",
    "for i in range(5):\n",
    "    event = kernel(queue, h_c.shape, (block_size, block_size), \n",
    "            d_c_buf, d_a_buf, d_b_buf)\n",
    "    event.wait()\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "# actual benchmark ------------------------------------------------------------\n",
    "t1 = time()\n",
    "\n",
    "count = 20\n",
    "for i in range(count):\n",
    "    event = kernel(queue, h_c.shape, (block_size, block_size),\n",
    "            d_c_buf, d_a_buf, d_b_buf)\n",
    "\n",
    "event.wait()\n",
    "\n",
    "gpu_time = (time()-t1)/count\n",
    "\n",
    "# transfer device -> host -----------------------------------------------------\n",
    "t1 = time()\n",
    "cl.enqueue_copy(queue, d_c_buf, h_c).wait()\n",
    "pull_time = time()-t1\n",
    "\n",
    "# timing output ---------------------------------------------------------------\n",
    "gpu_total_time = gpu_time+push_time+pull_time\n",
    "\n",
    "print(\"GPU push+compute+pull total [s]:\", gpu_total_time)\n",
    "print(\"GPU push [s]:\", push_time)\n",
    "print(\"GPU pull [s]:\", pull_time)\n",
    "print(\"GPU compute (host-timed) [s]:\", gpu_time)\n",
    "print(\"GPU compute (event-timed) [s]: \", (event.profile.end-event.profile.start)*1e-9)\n",
    "\n",
    "gflop = h_c.size * (a_width * 2.) / (1000**3.)\n",
    "gflops = gflop / gpu_time\n",
    "\n",
    "print()\n",
    "print(\"GFlops/s:\", gflops)\n",
    "\n",
    "# cpu comparison --------------------------------------------------------------\n",
    "t1 = time()\n",
    "h_c_cpu = numpy.dot(h_a,h_b)\n",
    "cpu_time = time()-t1\n",
    "\n",
    "print()\n",
    "print(\"GPU==CPU:\",numpy.allclose(h_c, h_c_cpu))\n",
    "print()\n",
    "print(\"CPU time (s)\", cpu_time)\n",
    "print()\n",
    "\n",
    "print(\"GPU speedup (with transfer): \", cpu_time/gpu_total_time)\n",
    "print(\"GPU speedup (without transfer): \", cpu_time/gpu_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e67aa6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
