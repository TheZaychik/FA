{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Зайцев Н. ПИ20-1В"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>  Использование TensorBoard в PyTorch</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы можете ознакомиться с работой этого кода на [`youtube`](https://www.youtube.com/watch?v=6CEld3hZgqc).\n",
    "\n",
    ".. raw:: html\n",
    "\n",
    "   <div style=\"margin-top:10px; margin-bottom:10px;\">\n",
    "     <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6CEld3hZgqc\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "   </div>\n",
    "\n",
    "Установка TensorBoard\n",
    "----------------\n",
    "\n",
    "Чтобы запустить этот код, вам потребуется установить PyTorch, TorchVision, Matplotlib и TensorBoard.\n",
    "\n",
    "При помощи `conda`:\n",
    "\n",
    "`!conda install pytorch torchvision -c pytorch`\n",
    "`!conda install matplotlib tensorboard`\n",
    "\n",
    "При помощи `pip`:\n",
    "\n",
    "`!pip install torch torchvision matplotlib tensorboard`\n",
    "\n",
    "Как только зависимости будут установлены, перезапустите этот ноутбук в\n",
    "среде Python, в которой вы их установили.\n",
    "\n",
    "Введение\n",
    "------------ \n",
    "В этом блокноте мы будем тренировать вариант LeNet-5 по набору данных Fashion-MNIST. Fashion-MNIST - это набор изображений различных предметов одежды, с десятью этикетками классов, указывающими тип изображенной одежды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 23:33:02.598145: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# нужно для моделей и их обучения в PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Наборы изображений и их преобразование\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# отображение и операции с матрицами\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# использование TensorBoard в PyTorch \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения в TensorBoard\n",
    "-----------------------------\n",
    "Давайте начнем с добавления образцов изображений из нашего набора данных в TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Собирайте наборы данных и готовьте их к использованию\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Храните отдельные выборки для обучения и проверки в ./data\n",
    "training_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set,\n",
    "                                              batch_size=4,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=2)\n",
    "\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set,\n",
    "                                                batch_size=4,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=2)\n",
    "\n",
    "# Метки классов\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Функция, способствующая просмотру изображений\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# Извлечение пакета 4 изображений\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Создание решетки изображений и их отображение\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше мы использовали Torch Vision и Matplotlib для создания визуальной сетки\n",
    "мини-пакета наших входных данных. Ниже мы используем вызов `add_image()` для\n",
    "`SummaryWriter`, чтобы записать изображение для использования TensorBoard, и\n",
    "мы также вызываем `flush()`, чтобы убедиться, что оно сразу записано на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Аргумент log_dir по умолчанию - \"runs\", но хорошо бы чтоб он был конкретным\n",
    "# torch.utils.tensorboard.SummaryWriter импортирован выше\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
    "\n",
    "# Запись данных изображения в log dir TensorBoard\n",
    "writer.add_image('Four Fashion-MNIST Images', img_grid)\n",
    "writer.flush()\n",
    "\n",
    "# To view, start TensorBoard on the command line with:\n",
    "#   tensorboard --logdir=runs\n",
    "# ...and open a browser tab to http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10916), started 0:11:01 ago. (Use '!kill 10916' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-93eecf1548535dd3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-93eecf1548535dd3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы запустите TensorBoard в командной строке и откроете его на новой вкладке браузера (обычно на [`localhost:6006`](http://localhost:6006), вы должны увидеть сетку изображений на вкладке IMAGES."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "Выполните загрузку данных из набора данных MNIST и проведите эксперимент по визуализации данных в Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                      download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                     download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(writer, loader, name):\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = next(dataiter)\n",
    "    img_grid = torchvision.utils.make_grid(images)\n",
    "    writer.add_image(name, img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "visualize_data(writer, trainloader, \"Training data\")\n",
    "visualize_data(writer, testloader, \"Test data\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение графиков скаляров для визуализации обучения\n",
    "--------------------------------------\n",
    "\n",
    "TensorBoard полезна для отслеживания прогресса и эффективности вашего\n",
    "обучения. Ниже мы запустим цикл обучения, отследим некоторые показатели и сохраним\n",
    "данные для использования TensorBoard.\n",
    "\n",
    "Давайте определим модель для классификации наших изображений, а также оптимизатор и\n",
    "функцию ошибки для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте обучим одну эпоху и оценим\n",
    "потери набора обучения и проверки каждые 1000 пакетов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "Batch 1000\n",
      "Batch 2000\n",
      "Batch 3000\n",
      "Batch 4000\n",
      "Batch 5000\n",
      "Batch 6000\n",
      "Batch 7000\n",
      "Batch 8000\n",
      "Batch 9000\n",
      "Batch 10000\n",
      "Batch 11000\n",
      "Batch 12000\n",
      "Batch 13000\n",
      "Batch 14000\n",
      "Batch 15000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "print(len(validation_loader))\n",
    "for epoch in range(1): \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(training_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            print('Batch {}'.format(i + 1))\n",
    "            running_vloss = 0.0\n",
    "            \n",
    "            net.train(False)\n",
    "            for j, vdata in enumerate(validation_loader, 0):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = net(vinputs)\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "                running_vloss += vloss.item()\n",
    "            net.train(True)\n",
    "            \n",
    "            avg_loss = running_loss / 1000\n",
    "            avg_vloss = running_vloss / len(validation_loader)\n",
    "            \n",
    "            writer.add_scalars('Training vs. Validation Loss',\n",
    "                            { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                            epoch * len(training_loader) + i)\n",
    "\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переключитесь на открытую TensorBoard и посмотрите на вкладку SCALARS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "Выполните классификацию данных MNIST описанной выше моделью и продолжите визуализацию обучения модели для эксперимента из Задания 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] training loss: 0.562, validation loss: 0.259\n",
      "Epoch [2] training loss: 0.123, validation loss: 0.127\n",
      "Epoch [3] training loss: 0.084, validation loss: 0.087\n",
      "Epoch [4] training loss: 0.067, validation loss: 0.060\n",
      "Epoch [5] training loss: 0.053, validation loss: 0.055\n",
      "Epoch [6] training loss: 0.049, validation loss: 0.045\n",
      "Epoch [7] training loss: 0.046, validation loss: 0.044\n",
      "Epoch [8] training loss: 0.041, validation loss: 0.038\n",
      "Epoch [9] training loss: 0.038, validation loss: 0.039\n",
      "Epoch [10] training loss: 0.035, validation loss: 0.037\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = nn.functional.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            running_loss = 0.0\n",
    "\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            outputs = net(inputs)\n",
    "            val_loss += nn.functional.cross_entropy(outputs, labels).item()\n",
    "    val_loss /= len(testloader)\n",
    "    print(f\"Epoch [{epoch + 1}] training loss: {running_loss / 1000:.3f}, validation loss: {val_loss:.3f}\")\n",
    "\n",
    "    writer.add_scalars('Train. vs. Val. Loss - MNIST Classification',\n",
    "                { 'Training' : running_loss / 1000, 'Validation' : val_loss },\n",
    "                epoch * len(trainloader) + i)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Визуализация модели\n",
    "----------------------\n",
    "\n",
    "TensorBoard также можно использовать для изучения потока данных в вашей модели.\n",
    "Для этого вызовите метод `add_graph()` с вводом модели и образца. Когда вы открываете\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Опять же, возьмите один мини-пакет изображений\n",
    "dataiter = iter(training_loader)\n",
    "images, labels =  next(dataiter)\n",
    "\n",
    "# add_graph() будет отслеживать ввод образца через вашу модель,\n",
    "# и визуализируйте его в виде графика.\n",
    "writer.add_graph(net, images)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда вы переключитесь на TensorBoard, вы должны увидеть вкладку GRAPHS. Дважды щелкните узел “NET”, чтобы увидеть слои и поток данных в вашей модели.\n",
    "\n",
    "Визуализация Вашего набора данных с помощью Embeddings\n",
    "----------------------------------------\n",
    "Изображения с разрешением 28 на 28, которые мы используем, могут быть смоделированы как 784-мерные векторы (28\\*28 = 784). Может быть поучительно спроецировать это на представление в более\n",
    "низком измерении. Метод `add_embedding()` проецирует набор данных на три измерения с наибольшей дисперсией и отображает их в виде интерактивной 3D-диаграммы. Функция `add_embedding()`\n",
    "метод делает это автоматически, проецируя в три измерения\n",
    "с наибольшей дисперсией.\n",
    "\n",
    "Ниже мы возьмем образец наших данных и создадим такое вложение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Select a random subset of data and corresponding labels\n",
    "def select_n_random(data, labels, n=100):\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# Extract a random subset of data\n",
    "images, labels = select_n_random(training_set.data, training_set.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[label] for label in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels, global_step=1,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.flush()\n",
    "#writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На сегодняшний день функция перестала работать `add_embedding()`. Будем надеяться, что это явление временное. При работе функции, если вы переключитесь на TensorBoard и выберете вкладку PROJECTOR, вы увидите 3D-представление проекции. Вы можете поворачивать и масштабировать модель. Изучите его в больших и малых масштабах и посмотрите, сможете ли вы обнаружить закономерности в проецируемых данных и кластеризации меток. В принципе проектор можно создать и средствами библиотеки `Tensorflow`.\n",
    "\n",
    "Для лучшей видимости рекомендуется:\n",
    "\n",
    "- Выберите “label” в раскрывающемся списке “Color by” слева.\n",
    "- Переключите значок ночного режима вверху, чтобы разместить светлые изображения на темном фоне.\n",
    "\n",
    "Другие ссылки\n",
    "---------------\n",
    "\n",
    "Для получения дополнительной информации ознакомьтесь с:\n",
    "\n",
    "- PyTorch документация [`torch.utils.tensorboard.SummaryWriter`](https://pytorch.org/docs/stable/tensorboard.html?highlight=summarywriter)\n",
    "- Tensorboard обучающий материал [`PyTorch.org Tutorials`](https://pytorch.org/tutorials/)\n",
    "- Для большей информации по TensorBoard, см. [`TensorBoard\n",
    "  documentation`](https://www.tensorflow.org/tensorboard)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
