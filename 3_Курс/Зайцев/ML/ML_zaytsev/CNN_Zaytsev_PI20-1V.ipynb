{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voijppXoSyo4"
   },
   "source": [
    "# Сверточные нейронные сети\n",
    "Для использования нейронных сетей этой тетради необходимо взять файлы из каталогов, использованных на предыдущей лекции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Зайцев Н. ПИ20-1В"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "executionInfo": {
     "elapsed": 4124,
     "status": "ok",
     "timestamp": 1603806696102,
     "user": {
      "displayName": "Владимир Попов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhmmWRUHxpJtOJtL-cAUWRTC2mi_nhK6jYL9K0CHA=s64",
      "userId": "11911063770407493537"
     },
     "user_tz": -180
    },
    "id": "NX2SHg7oSyo5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuzeBfEeSyo-"
   },
   "source": [
    "## CNNNet (или AlexNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "executionInfo": {
     "elapsed": 1348,
     "status": "ok",
     "timestamp": 1603806715010,
     "user": {
      "displayName": "Владимир Попов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhmmWRUHxpJtOJtL-cAUWRTC2mi_nhK6jYL9K0CHA=s64",
      "userId": "11911063770407493537"
     },
     "user_tz": -180
    },
    "id": "l46vsqFiSyo_"
   },
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNNNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128 * 6 * 6, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "executionInfo": {
     "elapsed": 1996,
     "status": "ok",
     "timestamp": 1603806721495,
     "user": {
      "displayName": "Владимир Попов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhmmWRUHxpJtOJtL-cAUWRTC2mi_nhK6jYL9K0CHA=s64",
      "userId": "11911063770407493537"
     },
     "user_tz": -180
    },
    "id": "zaEPbXTrSypD"
   },
   "outputs": [],
   "source": [
    "cnnnet = CNNNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "executionInfo": {
     "elapsed": 1317,
     "status": "ok",
     "timestamp": 1603806727581,
     "user": {
      "displayName": "Владимир Попов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhmmWRUHxpJtOJtL-cAUWRTC2mi_nhK6jYL9K0CHA=s64",
      "userId": "11911063770407493537"
     },
     "user_tz": -180
    },
    "id": "tdi6cD9xSypH"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "            correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n",
    "        valid_loss, num_correct / num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "executionInfo": {
     "elapsed": 399952,
     "status": "ok",
     "timestamp": 1603807404676,
     "user": {
      "displayName": "Владимир Попов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhmmWRUHxpJtOJtL-cAUWRTC2mi_nhK6jYL9K0CHA=s64",
      "userId": "11911063770407493537"
     },
     "user_tz": -180
    },
    "id": "XIWAHLKYSypN"
   },
   "outputs": [],
   "source": [
    "def check_image(path):\n",
    "    try:\n",
    "        im = Image.open(path)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((64,64)),    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "train_data_path = \"train\"\n",
    "train_data = torchvision.datasets.ImageFolder(root=train_data_path,transform=img_transforms, is_valid_file=check_image)\n",
    "\n",
    "val_data_path = \"val\"\n",
    "val_data = torchvision.datasets.ImageFolder(root=val_data_path,transform=img_transforms, is_valid_file=check_image)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,shuffle=True)\n",
    "val_data_loader  = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "id": "3Ty1ydiKSypQ"
   },
   "outputs": [],
   "source": [
    "cnnnet.to(device)\n",
    "optimizer = optim.Adam(cnnnet.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "id": "zyvGz2aDSypU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-343-f38d79bc5988>:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.69, Validation Loss: 0.68, accuracy = 0.73\n",
      "Epoch: 1, Training Loss: 0.67, Validation Loss: 0.67, accuracy = 0.64\n",
      "Epoch: 2, Training Loss: 0.65, Validation Loss: 0.65, accuracy = 0.69\n",
      "Epoch: 3, Training Loss: 0.63, Validation Loss: 0.62, accuracy = 0.69\n",
      "Epoch: 4, Training Loss: 0.61, Validation Loss: 0.60, accuracy = 0.70\n",
      "Epoch: 5, Training Loss: 0.59, Validation Loss: 0.56, accuracy = 0.73\n",
      "Epoch: 6, Training Loss: 0.57, Validation Loss: 0.54, accuracy = 0.75\n",
      "Epoch: 7, Training Loss: 0.55, Validation Loss: 0.55, accuracy = 0.75\n",
      "Epoch: 8, Training Loss: 0.54, Validation Loss: 0.50, accuracy = 0.77\n",
      "Epoch: 9, Training Loss: 0.53, Validation Loss: 0.52, accuracy = 0.77\n",
      "Epoch: 10, Training Loss: 0.52, Validation Loss: 0.53, accuracy = 0.77\n",
      "Epoch: 11, Training Loss: 0.51, Validation Loss: 0.56, accuracy = 0.72\n",
      "Epoch: 12, Training Loss: 0.50, Validation Loss: 0.52, accuracy = 0.76\n",
      "Epoch: 13, Training Loss: 0.49, Validation Loss: 0.47, accuracy = 0.76\n",
      "Epoch: 14, Training Loss: 0.48, Validation Loss: 0.53, accuracy = 0.74\n",
      "Epoch: 15, Training Loss: 0.48, Validation Loss: 0.50, accuracy = 0.77\n",
      "Epoch: 16, Training Loss: 0.47, Validation Loss: 0.47, accuracy = 0.77\n",
      "Epoch: 17, Training Loss: 0.47, Validation Loss: 0.41, accuracy = 0.77\n",
      "Epoch: 18, Training Loss: 0.48, Validation Loss: 0.44, accuracy = 0.77\n",
      "Epoch: 19, Training Loss: 0.47, Validation Loss: 0.48, accuracy = 0.77\n",
      "Epoch: 20, Training Loss: 0.47, Validation Loss: 0.50, accuracy = 0.75\n",
      "Epoch: 21, Training Loss: 0.46, Validation Loss: 0.45, accuracy = 0.77\n",
      "Epoch: 22, Training Loss: 0.46, Validation Loss: 0.43, accuracy = 0.77\n",
      "Epoch: 23, Training Loss: 0.46, Validation Loss: 0.43, accuracy = 0.77\n",
      "Epoch: 24, Training Loss: 0.45, Validation Loss: 0.42, accuracy = 0.78\n",
      "Epoch: 25, Training Loss: 0.44, Validation Loss: 0.41, accuracy = 0.78\n",
      "Epoch: 26, Training Loss: 0.45, Validation Loss: 0.40, accuracy = 0.79\n",
      "Epoch: 27, Training Loss: 0.44, Validation Loss: 0.43, accuracy = 0.77\n",
      "Epoch: 28, Training Loss: 0.44, Validation Loss: 0.44, accuracy = 0.78\n",
      "Epoch: 29, Training Loss: 0.44, Validation Loss: 0.43, accuracy = 0.77\n",
      "Epoch: 30, Training Loss: 0.43, Validation Loss: 0.51, accuracy = 0.75\n",
      "Epoch: 31, Training Loss: 0.44, Validation Loss: 0.40, accuracy = 0.79\n",
      "Epoch: 32, Training Loss: 0.44, Validation Loss: 0.43, accuracy = 0.78\n",
      "Epoch: 33, Training Loss: 0.43, Validation Loss: 0.40, accuracy = 0.80\n",
      "Epoch: 34, Training Loss: 0.43, Validation Loss: 0.41, accuracy = 0.80\n",
      "Epoch: 35, Training Loss: 0.42, Validation Loss: 0.44, accuracy = 0.77\n",
      "Epoch: 36, Training Loss: 0.43, Validation Loss: 0.40, accuracy = 0.81\n",
      "Epoch: 37, Training Loss: 0.42, Validation Loss: 0.43, accuracy = 0.79\n",
      "Epoch: 38, Training Loss: 0.41, Validation Loss: 0.36, accuracy = 0.82\n",
      "Epoch: 39, Training Loss: 0.42, Validation Loss: 0.40, accuracy = 0.80\n",
      "Epoch: 40, Training Loss: 0.42, Validation Loss: 0.38, accuracy = 0.79\n",
      "Epoch: 41, Training Loss: 0.41, Validation Loss: 0.34, accuracy = 0.86\n",
      "Epoch: 42, Training Loss: 0.41, Validation Loss: 0.38, accuracy = 0.79\n",
      "Epoch: 43, Training Loss: 0.40, Validation Loss: 0.44, accuracy = 0.77\n",
      "Epoch: 44, Training Loss: 0.41, Validation Loss: 0.36, accuracy = 0.81\n",
      "Epoch: 45, Training Loss: 0.41, Validation Loss: 0.36, accuracy = 0.81\n",
      "Epoch: 46, Training Loss: 0.40, Validation Loss: 0.42, accuracy = 0.79\n",
      "Epoch: 47, Training Loss: 0.40, Validation Loss: 0.40, accuracy = 0.81\n",
      "Epoch: 48, Training Loss: 0.41, Validation Loss: 0.39, accuracy = 0.80\n",
      "Epoch: 49, Training Loss: 0.40, Validation Loss: 0.38, accuracy = 0.80\n",
      "Epoch: 50, Training Loss: 0.39, Validation Loss: 0.38, accuracy = 0.81\n",
      "Epoch: 51, Training Loss: 0.40, Validation Loss: 0.43, accuracy = 0.79\n",
      "Epoch: 52, Training Loss: 0.40, Validation Loss: 0.36, accuracy = 0.83\n",
      "Epoch: 53, Training Loss: 0.38, Validation Loss: 0.39, accuracy = 0.81\n",
      "Epoch: 54, Training Loss: 0.38, Validation Loss: 0.37, accuracy = 0.80\n",
      "Epoch: 55, Training Loss: 0.39, Validation Loss: 0.36, accuracy = 0.80\n",
      "Epoch: 56, Training Loss: 0.39, Validation Loss: 0.34, accuracy = 0.84\n",
      "Epoch: 57, Training Loss: 0.38, Validation Loss: 0.43, accuracy = 0.79\n",
      "Epoch: 58, Training Loss: 0.39, Validation Loss: 0.42, accuracy = 0.79\n",
      "Epoch: 59, Training Loss: 0.37, Validation Loss: 0.41, accuracy = 0.79\n",
      "Epoch: 60, Training Loss: 0.37, Validation Loss: 0.40, accuracy = 0.81\n",
      "Epoch: 61, Training Loss: 0.38, Validation Loss: 0.34, accuracy = 0.85\n",
      "Epoch: 62, Training Loss: 0.37, Validation Loss: 0.38, accuracy = 0.82\n",
      "Epoch: 63, Training Loss: 0.37, Validation Loss: 0.38, accuracy = 0.85\n",
      "Epoch: 64, Training Loss: 0.37, Validation Loss: 0.37, accuracy = 0.83\n",
      "Epoch: 65, Training Loss: 0.37, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 66, Training Loss: 0.37, Validation Loss: 0.38, accuracy = 0.82\n",
      "Epoch: 67, Training Loss: 0.37, Validation Loss: 0.35, accuracy = 0.85\n",
      "Epoch: 68, Training Loss: 0.37, Validation Loss: 0.37, accuracy = 0.85\n",
      "Epoch: 69, Training Loss: 0.37, Validation Loss: 0.42, accuracy = 0.80\n",
      "Epoch: 70, Training Loss: 0.36, Validation Loss: 0.41, accuracy = 0.79\n",
      "Epoch: 71, Training Loss: 0.35, Validation Loss: 0.34, accuracy = 0.86\n",
      "Epoch: 72, Training Loss: 0.36, Validation Loss: 0.41, accuracy = 0.79\n",
      "Epoch: 73, Training Loss: 0.35, Validation Loss: 0.37, accuracy = 0.85\n",
      "Epoch: 74, Training Loss: 0.35, Validation Loss: 0.39, accuracy = 0.85\n",
      "Epoch: 75, Training Loss: 0.36, Validation Loss: 0.37, accuracy = 0.85\n",
      "Epoch: 76, Training Loss: 0.36, Validation Loss: 0.37, accuracy = 0.85\n",
      "Epoch: 77, Training Loss: 0.35, Validation Loss: 0.35, accuracy = 0.86\n",
      "Epoch: 78, Training Loss: 0.35, Validation Loss: 0.47, accuracy = 0.75\n",
      "Epoch: 79, Training Loss: 0.35, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 80, Training Loss: 0.35, Validation Loss: 0.29, accuracy = 0.86\n",
      "Epoch: 81, Training Loss: 0.34, Validation Loss: 0.35, accuracy = 0.87\n",
      "Epoch: 82, Training Loss: 0.34, Validation Loss: 0.38, accuracy = 0.82\n",
      "Epoch: 83, Training Loss: 0.34, Validation Loss: 0.35, accuracy = 0.85\n",
      "Epoch: 84, Training Loss: 0.34, Validation Loss: 0.39, accuracy = 0.81\n",
      "Epoch: 85, Training Loss: 0.35, Validation Loss: 0.41, accuracy = 0.81\n",
      "Epoch: 86, Training Loss: 0.34, Validation Loss: 0.36, accuracy = 0.87\n",
      "Epoch: 87, Training Loss: 0.34, Validation Loss: 0.40, accuracy = 0.82\n",
      "Epoch: 88, Training Loss: 0.34, Validation Loss: 0.41, accuracy = 0.81\n",
      "Epoch: 89, Training Loss: 0.34, Validation Loss: 0.35, accuracy = 0.87\n",
      "Epoch: 90, Training Loss: 0.34, Validation Loss: 0.33, accuracy = 0.87\n",
      "Epoch: 91, Training Loss: 0.33, Validation Loss: 0.37, accuracy = 0.85\n",
      "Epoch: 92, Training Loss: 0.32, Validation Loss: 0.37, accuracy = 0.85\n",
      "Epoch: 93, Training Loss: 0.34, Validation Loss: 0.33, accuracy = 0.87\n",
      "Epoch: 94, Training Loss: 0.33, Validation Loss: 0.34, accuracy = 0.87\n",
      "Epoch: 95, Training Loss: 0.33, Validation Loss: 0.40, accuracy = 0.82\n",
      "Epoch: 96, Training Loss: 0.33, Validation Loss: 0.38, accuracy = 0.84\n",
      "Epoch: 97, Training Loss: 0.33, Validation Loss: 0.32, accuracy = 0.88\n",
      "Epoch: 98, Training Loss: 0.32, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 99, Training Loss: 0.33, Validation Loss: 0.38, accuracy = 0.84\n",
      "Epoch: 100, Training Loss: 0.32, Validation Loss: 0.32, accuracy = 0.87\n",
      "Epoch: 101, Training Loss: 0.33, Validation Loss: 0.36, accuracy = 0.86\n",
      "Epoch: 102, Training Loss: 0.31, Validation Loss: 0.38, accuracy = 0.85\n",
      "Epoch: 103, Training Loss: 0.31, Validation Loss: 0.36, accuracy = 0.86\n",
      "Epoch: 104, Training Loss: 0.31, Validation Loss: 0.35, accuracy = 0.87\n",
      "Epoch: 105, Training Loss: 0.32, Validation Loss: 0.34, accuracy = 0.87\n",
      "Epoch: 106, Training Loss: 0.31, Validation Loss: 0.35, accuracy = 0.86\n",
      "Epoch: 107, Training Loss: 0.31, Validation Loss: 0.30, accuracy = 0.87\n",
      "Epoch: 108, Training Loss: 0.31, Validation Loss: 0.31, accuracy = 0.89\n",
      "Epoch: 109, Training Loss: 0.31, Validation Loss: 0.33, accuracy = 0.87\n",
      "Epoch: 110, Training Loss: 0.30, Validation Loss: 0.34, accuracy = 0.87\n",
      "Epoch: 111, Training Loss: 0.31, Validation Loss: 0.38, accuracy = 0.84\n",
      "Epoch: 112, Training Loss: 0.31, Validation Loss: 0.34, accuracy = 0.87\n",
      "Epoch: 113, Training Loss: 0.31, Validation Loss: 0.31, accuracy = 0.87\n",
      "Epoch: 114, Training Loss: 0.30, Validation Loss: 0.32, accuracy = 0.88\n",
      "Epoch: 115, Training Loss: 0.31, Validation Loss: 0.41, accuracy = 0.81\n",
      "Epoch: 116, Training Loss: 0.30, Validation Loss: 0.40, accuracy = 0.82\n",
      "Epoch: 117, Training Loss: 0.30, Validation Loss: 0.35, accuracy = 0.85\n",
      "Epoch: 118, Training Loss: 0.30, Validation Loss: 0.35, accuracy = 0.86\n",
      "Epoch: 119, Training Loss: 0.31, Validation Loss: 0.31, accuracy = 0.87\n",
      "Epoch: 120, Training Loss: 0.30, Validation Loss: 0.36, accuracy = 0.86\n",
      "Epoch: 121, Training Loss: 0.29, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 122, Training Loss: 0.30, Validation Loss: 0.28, accuracy = 0.88\n",
      "Epoch: 123, Training Loss: 0.30, Validation Loss: 0.37, accuracy = 0.85\n",
      "Epoch: 124, Training Loss: 0.30, Validation Loss: 0.32, accuracy = 0.89\n",
      "Epoch: 125, Training Loss: 0.28, Validation Loss: 0.29, accuracy = 0.88\n",
      "Epoch: 126, Training Loss: 0.29, Validation Loss: 0.37, accuracy = 0.85\n",
      "Epoch: 127, Training Loss: 0.29, Validation Loss: 0.33, accuracy = 0.87\n",
      "Epoch: 128, Training Loss: 0.28, Validation Loss: 0.33, accuracy = 0.88\n",
      "Epoch: 129, Training Loss: 0.28, Validation Loss: 0.33, accuracy = 0.87\n",
      "Epoch: 130, Training Loss: 0.29, Validation Loss: 0.33, accuracy = 0.87\n",
      "Epoch: 131, Training Loss: 0.28, Validation Loss: 0.34, accuracy = 0.87\n",
      "Epoch: 132, Training Loss: 0.28, Validation Loss: 0.34, accuracy = 0.86\n",
      "Epoch: 133, Training Loss: 0.27, Validation Loss: 0.32, accuracy = 0.88\n",
      "Epoch: 134, Training Loss: 0.28, Validation Loss: 0.30, accuracy = 0.88\n",
      "Epoch: 135, Training Loss: 0.28, Validation Loss: 0.30, accuracy = 0.88\n",
      "Epoch: 136, Training Loss: 0.28, Validation Loss: 0.32, accuracy = 0.88\n",
      "Epoch: 137, Training Loss: 0.29, Validation Loss: 0.32, accuracy = 0.88\n",
      "Epoch: 138, Training Loss: 0.29, Validation Loss: 0.29, accuracy = 0.88\n",
      "Epoch: 139, Training Loss: 0.28, Validation Loss: 0.37, accuracy = 0.84\n",
      "Epoch: 140, Training Loss: 0.27, Validation Loss: 0.34, accuracy = 0.85\n",
      "Epoch: 141, Training Loss: 0.28, Validation Loss: 0.31, accuracy = 0.88\n",
      "Epoch: 142, Training Loss: 0.28, Validation Loss: 0.32, accuracy = 0.88\n",
      "Epoch: 143, Training Loss: 0.28, Validation Loss: 0.30, accuracy = 0.88\n",
      "Epoch: 144, Training Loss: 0.28, Validation Loss: 0.31, accuracy = 0.88\n",
      "Epoch: 145, Training Loss: 0.28, Validation Loss: 0.32, accuracy = 0.88\n",
      "Epoch: 146, Training Loss: 0.27, Validation Loss: 0.32, accuracy = 0.88\n",
      "Epoch: 147, Training Loss: 0.28, Validation Loss: 0.32, accuracy = 0.88\n",
      "Epoch: 148, Training Loss: 0.27, Validation Loss: 0.37, accuracy = 0.85\n",
      "Epoch: 149, Training Loss: 0.27, Validation Loss: 0.36, accuracy = 0.85\n",
      "Epoch: 150, Training Loss: 0.27, Validation Loss: 0.35, accuracy = 0.85\n",
      "Epoch: 151, Training Loss: 0.27, Validation Loss: 0.36, accuracy = 0.86\n",
      "Epoch: 152, Training Loss: 0.27, Validation Loss: 0.38, accuracy = 0.85\n",
      "Epoch: 153, Training Loss: 0.26, Validation Loss: 0.30, accuracy = 0.88\n",
      "Epoch: 154, Training Loss: 0.26, Validation Loss: 0.38, accuracy = 0.83\n",
      "Epoch: 155, Training Loss: 0.26, Validation Loss: 0.33, accuracy = 0.87\n",
      "Epoch: 156, Training Loss: 0.27, Validation Loss: 0.32, accuracy = 0.88\n",
      "Epoch: 157, Training Loss: 0.26, Validation Loss: 0.32, accuracy = 0.88\n",
      "Epoch: 158, Training Loss: 0.25, Validation Loss: 0.32, accuracy = 0.87\n",
      "Epoch: 159, Training Loss: 0.27, Validation Loss: 0.35, accuracy = 0.85\n",
      "Epoch: 160, Training Loss: 0.27, Validation Loss: 0.34, accuracy = 0.85\n",
      "Epoch: 161, Training Loss: 0.25, Validation Loss: 0.32, accuracy = 0.87\n",
      "Epoch: 162, Training Loss: 0.26, Validation Loss: 0.34, accuracy = 0.86\n",
      "Epoch: 163, Training Loss: 0.25, Validation Loss: 0.30, accuracy = 0.88\n",
      "Epoch: 164, Training Loss: 0.26, Validation Loss: 0.32, accuracy = 0.88\n",
      "Epoch: 165, Training Loss: 0.27, Validation Loss: 0.29, accuracy = 0.89\n",
      "Epoch: 166, Training Loss: 0.25, Validation Loss: 0.35, accuracy = 0.86\n",
      "Epoch: 167, Training Loss: 0.26, Validation Loss: 0.33, accuracy = 0.87\n",
      "Epoch: 168, Training Loss: 0.25, Validation Loss: 0.30, accuracy = 0.88\n",
      "Epoch: 169, Training Loss: 0.26, Validation Loss: 0.29, accuracy = 0.89\n",
      "Epoch: 170, Training Loss: 0.26, Validation Loss: 0.32, accuracy = 0.88\n",
      "Epoch: 171, Training Loss: 0.26, Validation Loss: 0.28, accuracy = 0.89\n",
      "Epoch: 172, Training Loss: 0.25, Validation Loss: 0.31, accuracy = 0.89\n",
      "Epoch: 173, Training Loss: 0.25, Validation Loss: 0.34, accuracy = 0.87\n",
      "Epoch: 174, Training Loss: 0.25, Validation Loss: 0.39, accuracy = 0.83\n",
      "Epoch: 175, Training Loss: 0.25, Validation Loss: 0.31, accuracy = 0.88\n",
      "Epoch: 176, Training Loss: 0.24, Validation Loss: 0.37, accuracy = 0.85\n",
      "Epoch: 177, Training Loss: 0.26, Validation Loss: 0.32, accuracy = 0.87\n",
      "Epoch: 178, Training Loss: 0.24, Validation Loss: 0.28, accuracy = 0.90\n",
      "Epoch: 179, Training Loss: 0.25, Validation Loss: 0.29, accuracy = 0.88\n",
      "Epoch: 180, Training Loss: 0.24, Validation Loss: 0.35, accuracy = 0.86\n",
      "Epoch: 181, Training Loss: 0.24, Validation Loss: 0.34, accuracy = 0.87\n",
      "Epoch: 182, Training Loss: 0.23, Validation Loss: 0.32, accuracy = 0.87\n",
      "Epoch: 183, Training Loss: 0.25, Validation Loss: 0.29, accuracy = 0.88\n",
      "Epoch: 184, Training Loss: 0.24, Validation Loss: 0.26, accuracy = 0.89\n",
      "Epoch: 185, Training Loss: 0.25, Validation Loss: 0.31, accuracy = 0.88\n",
      "Epoch: 186, Training Loss: 0.23, Validation Loss: 0.32, accuracy = 0.87\n",
      "Epoch: 187, Training Loss: 0.24, Validation Loss: 0.29, accuracy = 0.88\n",
      "Epoch: 188, Training Loss: 0.25, Validation Loss: 0.29, accuracy = 0.89\n",
      "Epoch: 189, Training Loss: 0.24, Validation Loss: 0.33, accuracy = 0.87\n",
      "Epoch: 190, Training Loss: 0.23, Validation Loss: 0.33, accuracy = 0.87\n",
      "Epoch: 191, Training Loss: 0.23, Validation Loss: 0.32, accuracy = 0.87\n",
      "Epoch: 192, Training Loss: 0.24, Validation Loss: 0.33, accuracy = 0.87\n",
      "Epoch: 193, Training Loss: 0.23, Validation Loss: 0.33, accuracy = 0.87\n",
      "Epoch: 194, Training Loss: 0.24, Validation Loss: 0.31, accuracy = 0.88\n",
      "Epoch: 195, Training Loss: 0.24, Validation Loss: 0.33, accuracy = 0.86\n",
      "Epoch: 196, Training Loss: 0.22, Validation Loss: 0.32, accuracy = 0.87\n",
      "Epoch: 197, Training Loss: 0.22, Validation Loss: 0.30, accuracy = 0.88\n",
      "Epoch: 198, Training Loss: 0.23, Validation Loss: 0.30, accuracy = 0.88\n",
      "Epoch: 199, Training Loss: 0.22, Validation Loss: 0.29, accuracy = 0.88\n"
     ]
    }
   ],
   "source": [
    "train(cnnnet, optimizer,torch.nn.CrossEntropyLoss(), train_data_loader,val_data_loader, epochs=200, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "Передайте в модель одно из изображений в проверочной выборке и получите предсказание классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_image(image_path, model):\n",
    "    img = Image.open(image_path)\n",
    "    mean = [0.485, 0.456, 0.406] \n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    transform_norm = transforms.Compose([\n",
    "                        transforms.ToTensor(), \n",
    "                        transforms.Resize((64,64)),\n",
    "                        transforms.Normalize(mean, std)])\n",
    "    img_normalized = transform_norm(img).float()\n",
    "    img_normalized = img_normalized.unsqueeze_(0)\n",
    "    img_normalized = img_normalized.to(device)\n",
    "    with torch.no_grad():\n",
    "        model.eval()  \n",
    "        output = model(img_normalized)\n",
    "        index = output.data.cpu().numpy().argmax()\n",
    "        classes = train_data.classes\n",
    "        class_name = classes[index]\n",
    "        return class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image(path):\n",
    "    try:\n",
    "        im = Image.open(path)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "while True:\n",
    "    dirname = random.choice([\"test/cat/\", 'test/fish/'])\n",
    "    filename = random.choice(os.listdir(dirname))\n",
    "    path = os.path.join(dirname, filename)\n",
    "    if check_image(path):\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "predict_class = pre_image(path, cnnnet)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(np.asarray(Image.open(path)), cmap='gray_r')\n",
    "plt.title(f\"Prediction: {predict_class}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "Настройте модель CNNNet на предсказание данных MNIST, выполните обучение модели и получите предсказание на случайно выбранном данном. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNNNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/938], Loss: 0.3228\n",
      "Epoch [1/10], Step [200/938], Loss: 0.2532\n",
      "Epoch [1/10], Step [300/938], Loss: 0.3047\n",
      "Epoch [1/10], Step [400/938], Loss: 0.1252\n",
      "Epoch [1/10], Step [500/938], Loss: 0.0696\n",
      "Epoch [1/10], Step [600/938], Loss: 0.2188\n",
      "Epoch [1/10], Step [700/938], Loss: 0.1911\n",
      "Epoch [1/10], Step [800/938], Loss: 0.0737\n",
      "Epoch [1/10], Step [900/938], Loss: 0.2830\n",
      "Epoch [1/10], Validation Loss: 0.0510, Validation Accuracy: 98.31%\n",
      "Epoch [2/10], Step [100/938], Loss: 0.2112\n",
      "Epoch [2/10], Step [200/938], Loss: 0.0447\n",
      "Epoch [2/10], Step [300/938], Loss: 0.0893\n",
      "Epoch [2/10], Step [400/938], Loss: 0.0598\n",
      "Epoch [2/10], Step [500/938], Loss: 0.0397\n",
      "Epoch [2/10], Step [600/938], Loss: 0.0942\n",
      "Epoch [2/10], Step [700/938], Loss: 0.0681\n",
      "Epoch [2/10], Step [800/938], Loss: 0.0836\n",
      "Epoch [2/10], Step [900/938], Loss: 0.0524\n",
      "Epoch [2/10], Validation Loss: 0.0348, Validation Accuracy: 98.86%\n",
      "Epoch [3/10], Step [100/938], Loss: 0.0826\n",
      "Epoch [3/10], Step [200/938], Loss: 0.0464\n",
      "Epoch [3/10], Step [300/938], Loss: 0.0295\n",
      "Epoch [3/10], Step [400/938], Loss: 0.0621\n",
      "Epoch [3/10], Step [500/938], Loss: 0.0740\n",
      "Epoch [3/10], Step [600/938], Loss: 0.1092\n",
      "Epoch [3/10], Step [700/938], Loss: 0.0239\n",
      "Epoch [3/10], Step [800/938], Loss: 0.0458\n",
      "Epoch [3/10], Step [900/938], Loss: 0.2286\n",
      "Epoch [3/10], Validation Loss: 0.0300, Validation Accuracy: 99.04%\n",
      "Epoch [4/10], Step [100/938], Loss: 0.0315\n",
      "Epoch [4/10], Step [200/938], Loss: 0.1606\n",
      "Epoch [4/10], Step [300/938], Loss: 0.1013\n",
      "Epoch [4/10], Step [400/938], Loss: 0.1097\n",
      "Epoch [4/10], Step [500/938], Loss: 0.0770\n",
      "Epoch [4/10], Step [600/938], Loss: 0.0576\n",
      "Epoch [4/10], Step [700/938], Loss: 0.0982\n",
      "Epoch [4/10], Step [800/938], Loss: 0.1817\n",
      "Epoch [4/10], Step [900/938], Loss: 0.0716\n",
      "Epoch [4/10], Validation Loss: 0.0292, Validation Accuracy: 98.99%\n",
      "Epoch [5/10], Step [100/938], Loss: 0.0598\n",
      "Epoch [5/10], Step [200/938], Loss: 0.0626\n",
      "Epoch [5/10], Step [300/938], Loss: 0.0141\n",
      "Epoch [5/10], Step [400/938], Loss: 0.0569\n",
      "Epoch [5/10], Step [500/938], Loss: 0.0316\n",
      "Epoch [5/10], Step [600/938], Loss: 0.0134\n",
      "Epoch [5/10], Step [700/938], Loss: 0.3132\n",
      "Epoch [5/10], Step [800/938], Loss: 0.0358\n",
      "Epoch [5/10], Step [900/938], Loss: 0.0078\n",
      "Epoch [5/10], Validation Loss: 0.0250, Validation Accuracy: 99.18%\n",
      "Epoch [6/10], Step [100/938], Loss: 0.0072\n",
      "Epoch [6/10], Step [200/938], Loss: 0.1128\n",
      "Epoch [6/10], Step [300/938], Loss: 0.0818\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0329\n",
      "Epoch [6/10], Step [500/938], Loss: 0.0780\n",
      "Epoch [6/10], Step [600/938], Loss: 0.0209\n",
      "Epoch [6/10], Step [700/938], Loss: 0.1251\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0326\n",
      "Epoch [6/10], Step [900/938], Loss: 0.1355\n",
      "Epoch [6/10], Validation Loss: 0.0240, Validation Accuracy: 99.25%\n",
      "Epoch [7/10], Step [100/938], Loss: 0.0186\n",
      "Epoch [7/10], Step [200/938], Loss: 0.0845\n",
      "Epoch [7/10], Step [300/938], Loss: 0.0738\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0345\n",
      "Epoch [7/10], Step [500/938], Loss: 0.0250\n",
      "Epoch [7/10], Step [600/938], Loss: 0.0828\n",
      "Epoch [7/10], Step [700/938], Loss: 0.0014\n",
      "Epoch [7/10], Step [800/938], Loss: 0.1204\n",
      "Epoch [7/10], Step [900/938], Loss: 0.0063\n",
      "Epoch [7/10], Validation Loss: 0.0262, Validation Accuracy: 99.11%\n",
      "Epoch [8/10], Step [100/938], Loss: 0.0058\n",
      "Epoch [8/10], Step [200/938], Loss: 0.0351\n",
      "Epoch [8/10], Step [300/938], Loss: 0.0480\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0422\n",
      "Epoch [8/10], Step [500/938], Loss: 0.0365\n",
      "Epoch [8/10], Step [600/938], Loss: 0.0520\n",
      "Epoch [8/10], Step [700/938], Loss: 0.0128\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0033\n",
      "Epoch [8/10], Step [900/938], Loss: 0.0027\n",
      "Epoch [8/10], Validation Loss: 0.0241, Validation Accuracy: 99.17%\n",
      "Epoch [9/10], Step [100/938], Loss: 0.1267\n",
      "Epoch [9/10], Step [200/938], Loss: 0.0380\n",
      "Epoch [9/10], Step [300/938], Loss: 0.0099\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0372\n",
      "Epoch [9/10], Step [500/938], Loss: 0.0475\n",
      "Epoch [9/10], Step [600/938], Loss: 0.0246\n",
      "Epoch [9/10], Step [700/938], Loss: 0.0527\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0405\n",
      "Epoch [9/10], Step [900/938], Loss: 0.0520\n",
      "Epoch [9/10], Validation Loss: 0.0220, Validation Accuracy: 99.25%\n",
      "Epoch [10/10], Step [100/938], Loss: 0.0015\n",
      "Epoch [10/10], Step [200/938], Loss: 0.0118\n",
      "Epoch [10/10], Step [300/938], Loss: 0.0790\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0420\n",
      "Epoch [10/10], Step [500/938], Loss: 0.0203\n",
      "Epoch [10/10], Step [600/938], Loss: 0.0160\n",
      "Epoch [10/10], Step [700/938], Loss: 0.0261\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0402\n",
      "Epoch [10/10], Step [900/938], Loss: 0.0212\n",
      "Epoch [10/10], Validation Loss: 0.0203, Validation Accuracy: 99.40%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, len(train_loader), loss.item()))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_loss /= len(test_loader)\n",
    "        print('Epoch [{}/{}], Validation Loss: {:.4f}, Validation Accuracy: {:.2f}%'.format(epoch + 1, num_epochs, val_loss, val_accuracy))\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 99.4 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image, label = test_dataset[random.randint(0, len(test_dataset))]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(image.unsqueeze(0))\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image.squeeze(), cmap='gray_r')\n",
    "plt.title(f\"Prediction: {predicted.item()}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTo_KFw-SypY"
   },
   "source": [
    "## Загрузка предобученных моделей \n",
    "\n",
    "Существует два способа загрузки предварительно подготовленных моделей изображений с помощью PyTorch. Во-первых, вы можете использовать библиотеку `torch vision.models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uh-rCmjSSypY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /Users/nikitazaytsev/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
      "100%|██████████| 233M/233M [00:03<00:00, 61.5MB/s] \n",
      "/usr/local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "alexnet = models.alexnet(num_classes=1000, pretrained=True)\n",
    "resnet50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dlLGMTOfSypf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XKu1AS9DSypi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
